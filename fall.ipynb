{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "images_path = 'train folder path'\n",
    "image_files = os.listdir(images_path)[:9]\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for ax, image in zip(axes.flatten(), image_files):\n",
    "    img = plt.imread(os.path.join(images_path, image))\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "target_size = (640, 640)\n",
    "train_images = []\n",
    "for image in os.listdir(images_path):\n",
    "    img = cv2.imread(os.path.join(images_path, image))\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    train_images.append(img)\n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# model = YOLO('yolo11n.yaml')  # build a new model from scratch\n",
    "model = YOLO('yolo11s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!yolo task=detect mode=train model=yolo11s.pt data=\"yaml file path\" epochs=100 device=0 batch=32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = YOLO('/content/yolo11s.pt')\n",
    "video_path = '/content/test.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "# Get video details\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "out = cv2.VideoWriter('/content/output.mp4', cv2.VideoWriter_fourcc(*'mp4v'), fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Run YOLO model on the frame\n",
    "    results = model(frame)\n",
    "    # Draw detections\n",
    "    for r in results:\n",
    "      # print(r.boxes)\n",
    "      # break\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = box.conf[0]\n",
    "            cls = int(box.cls[0])  # Get class ID\n",
    "\n",
    "            # Assuming \"falling person\" class ID is 0\n",
    "            if cls==0 and conf > 0.7:\n",
    "                label = f\"Fall {conf:.2f}\"\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)  # Red box\n",
    "                cv2.putText(frame, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "\n",
    "    # Write frame to output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
